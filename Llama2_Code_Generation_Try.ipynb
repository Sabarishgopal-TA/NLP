{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c99aff4cfd664ae8a165a27bea0566c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4b64cab6b7b418c8a2575ee26839039",
              "IPY_MODEL_c3a4fedc73b3480089ef9d13381471ed",
              "IPY_MODEL_bf722f71c61b4285bcbbf32fd619b3a6"
            ],
            "layout": "IPY_MODEL_fd11a6148b704c5b9142c5e8de2d3b25"
          }
        },
        "e4b64cab6b7b418c8a2575ee26839039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0bcdaf940d14ad796fc7ac46c8e1e64",
            "placeholder": "​",
            "style": "IPY_MODEL_b6e821c974674f2290c354238d6c919c",
            "value": "Upload 2 LFS files: 100%"
          }
        },
        "c3a4fedc73b3480089ef9d13381471ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eeba50e8242c4753bfc0ea48e03f9078",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a1f3340688d408092adade75f4baac4",
            "value": 2
          }
        },
        "bf722f71c61b4285bcbbf32fd619b3a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c887ca9b0eb44fdb8608bf36b5db5c5",
            "placeholder": "​",
            "style": "IPY_MODEL_e4698337e6b843afac706ab657ca6af9",
            "value": " 2/2 [06:36&lt;00:00, 396.47s/it]"
          }
        },
        "fd11a6148b704c5b9142c5e8de2d3b25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0bcdaf940d14ad796fc7ac46c8e1e64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6e821c974674f2290c354238d6c919c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eeba50e8242c4753bfc0ea48e03f9078": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a1f3340688d408092adade75f4baac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c887ca9b0eb44fdb8608bf36b5db5c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4698337e6b843afac706ab657ca6af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1af01f1f1aac42b8bff46fe4df8a59ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eee8731f316244eda5ff0765fd12bf85",
              "IPY_MODEL_f135278e410f4b708435bb80fb630bcf",
              "IPY_MODEL_2e6fc79bf5c149d6b0bc5c52e18debc7"
            ],
            "layout": "IPY_MODEL_a4b0debc025444a59abd6953b3512c0d"
          }
        },
        "eee8731f316244eda5ff0765fd12bf85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_130120644beb48acbc038651459af43c",
            "placeholder": "​",
            "style": "IPY_MODEL_bf77e97593a349718bdb5fd9bfd28fe3",
            "value": "pytorch_model-00001-of-00002.bin: 100%"
          }
        },
        "f135278e410f4b708435bb80fb630bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7292741953e47699540ef8712fc0d8d",
            "max": 9976637886,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9434350b1b9c4060812feb9ecbf63278",
            "value": 9976637886
          }
        },
        "2e6fc79bf5c149d6b0bc5c52e18debc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b29647e268414329be56047e522e28b9",
            "placeholder": "​",
            "style": "IPY_MODEL_27bb18a199ca47108c7a61e9c443de36",
            "value": " 9.98G/9.98G [06:35&lt;00:00, 25.8MB/s]"
          }
        },
        "a4b0debc025444a59abd6953b3512c0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "130120644beb48acbc038651459af43c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf77e97593a349718bdb5fd9bfd28fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7292741953e47699540ef8712fc0d8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9434350b1b9c4060812feb9ecbf63278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b29647e268414329be56047e522e28b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27bb18a199ca47108c7a61e9c443de36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33ebb868f3e846f6af1a1a2a8ad6a3cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f73f8b4d4da4e74adc135f2a2f6ee65",
              "IPY_MODEL_68da6e6e69c8419895bea2068760534e",
              "IPY_MODEL_6dc1a868e08c4c3b8315116d2c46573b"
            ],
            "layout": "IPY_MODEL_7a5d714c17374104bb6f5caaa5541c10"
          }
        },
        "1f73f8b4d4da4e74adc135f2a2f6ee65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b6c59a51359453c926bfcddb3d0f0ea",
            "placeholder": "​",
            "style": "IPY_MODEL_dac3669f18284161a58d52f26dffb761",
            "value": "pytorch_model-00002-of-00002.bin: 100%"
          }
        },
        "68da6e6e69c8419895bea2068760534e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3511f489f6d47cc8d404ab6f367b29f",
            "max": 3500316627,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20670478612f4b1a8a5f23d71a2609a7",
            "value": 3500316627
          }
        },
        "6dc1a868e08c4c3b8315116d2c46573b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b463153ec04749e38540389efa2981f7",
            "placeholder": "​",
            "style": "IPY_MODEL_2bb3d36d248a48fba364f14d9e840306",
            "value": " 3.50G/3.50G [02:27&lt;00:00, 26.4MB/s]"
          }
        },
        "7a5d714c17374104bb6f5caaa5541c10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b6c59a51359453c926bfcddb3d0f0ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dac3669f18284161a58d52f26dffb761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3511f489f6d47cc8d404ab6f367b29f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20670478612f4b1a8a5f23d71a2609a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b463153ec04749e38540389efa2981f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bb3d36d248a48fba364f14d9e840306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87de37ef2dc34cfda9d179a499e50463": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71a287c30634401bb99286a0ecab6fde",
              "IPY_MODEL_fb3b227610924c9eaea8f4f4f99dbd39",
              "IPY_MODEL_6298f7958c484967bd91d459ab514cc0"
            ],
            "layout": "IPY_MODEL_120d4b07606949d28790e9e5b3e3f931"
          }
        },
        "71a287c30634401bb99286a0ecab6fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_757ae8f937044623bb1f60722ac1573a",
            "placeholder": "​",
            "style": "IPY_MODEL_826356db10e942b38576855b1f0c54a3",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "fb3b227610924c9eaea8f4f4f99dbd39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83022808e74e40d9b3af7de668ff8505",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d84706b1cd3340aeacec7340d6e81c6e",
            "value": 2
          }
        },
        "6298f7958c484967bd91d459ab514cc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb249cb5e74e46bc81d48399bb422f85",
            "placeholder": "​",
            "style": "IPY_MODEL_ee1d34c35f3b4b8799b6047329ce1734",
            "value": " 2/2 [01:16&lt;00:00, 34.57s/it]"
          }
        },
        "120d4b07606949d28790e9e5b3e3f931": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "757ae8f937044623bb1f60722ac1573a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "826356db10e942b38576855b1f0c54a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83022808e74e40d9b3af7de668ff8505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d84706b1cd3340aeacec7340d6e81c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb249cb5e74e46bc81d48399bb422f85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee1d34c35f3b4b8799b6047329ce1734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f69919bcbf78422283d4a563bee0f7eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ac3a69109a241c68c21bcda25ca62ff",
              "IPY_MODEL_ccb497cf46e249129d13e73f9b1a26a7",
              "IPY_MODEL_40703ce07ae84726b82e923de16a2583"
            ],
            "layout": "IPY_MODEL_c5573a7a892d48df909ca894e088fda4"
          }
        },
        "0ac3a69109a241c68c21bcda25ca62ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cce49e3f6134d78aa60cab6ebafa2ca",
            "placeholder": "​",
            "style": "IPY_MODEL_7424a35e355c4844a7b882d4249b5fad",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "ccb497cf46e249129d13e73f9b1a26a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_667b211332a0449494084da0acb24564",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14b57836cbcb4fc8855503b8112769ac",
            "value": 2
          }
        },
        "40703ce07ae84726b82e923de16a2583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24dc4767f289473d9ebefea7965dda3e",
            "placeholder": "​",
            "style": "IPY_MODEL_c8c96a733fc848e98972e1c7773b6dc9",
            "value": " 2/2 [01:12&lt;00:00, 33.23s/it]"
          }
        },
        "c5573a7a892d48df909ca894e088fda4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cce49e3f6134d78aa60cab6ebafa2ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7424a35e355c4844a7b882d4249b5fad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "667b211332a0449494084da0acb24564": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14b57836cbcb4fc8855503b8112769ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24dc4767f289473d9ebefea7965dda3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8c96a733fc848e98972e1c7773b6dc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tune Llama 2 in Google Colab\n",
        "> 🗣️ Large Language Model Course\n",
        "\n",
        "❤️ Created by [@maximelabonne](https://twitter.com/maximelabonne), based on Younes Belkada's [GitHub Gist](https://gist.github.com/younesbelkada/9f7f75c94bdc1981c8ca5cc937d4a4da). Special thanks to Tolga HOŞGÖR for his solution to empty the VRAM.\n",
        "\n",
        "This notebook runs on a T4 GPU. (Last update: 24 Aug 2023)\n"
      ],
      "metadata": {
        "id": "OSHlAbqzDFDq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GLXwJqbjtPho"
      },
      "outputs": [],
      "source": [
        "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "from peft import LoraConfig, PeftModel\n",
        "from trl import SFTTrainer"
      ],
      "metadata": {
        "id": "nAMzy_0FtaUZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The model that you want to train from the Hugging Face hub\n",
        "model_name = \"NousResearch/Llama-2-7b-chat-hf\"\n",
        "\n",
        "# The instruction dataset to use\n",
        "# dataset_name = \"mlabonne/guanaco-llama2-1k\"\n",
        "dataset_name = \"mbpp\"\n",
        "\n",
        "# Fine-tuned model name\n",
        "new_model = \"llama-2-7b-mbpp\"\n",
        "\n",
        "################################################################################\n",
        "# QLoRA parameters\n",
        "################################################################################\n",
        "\n",
        "# LoRA attention dimension\n",
        "lora_r = 64\n",
        "\n",
        "# Alpha parameter for LoRA scaling\n",
        "lora_alpha = 16\n",
        "\n",
        "# Dropout probability for LoRA layers\n",
        "lora_dropout = 0.1\n",
        "\n",
        "################################################################################\n",
        "# bitsandbytes parameters\n",
        "################################################################################\n",
        "\n",
        "# Activate 4-bit precision base model loading\n",
        "use_4bit = True\n",
        "\n",
        "# Compute dtype for 4-bit base models\n",
        "bnb_4bit_compute_dtype = \"float16\"\n",
        "\n",
        "# Quantization type (fp4 or nf4)\n",
        "bnb_4bit_quant_type = \"nf4\"\n",
        "\n",
        "# Activate nested quantization for 4-bit base models (double quantization)\n",
        "use_nested_quant = False\n",
        "\n",
        "################################################################################\n",
        "# TrainingArguments parameters\n",
        "################################################################################\n",
        "\n",
        "# Output directory where the model predictions and checkpoints will be stored\n",
        "output_dir = \"./results\"\n",
        "\n",
        "# Number of training epochs\n",
        "num_train_epochs = 2\n",
        "\n",
        "# Enable fp16/bf16 training (set bf16 to True with an A100)\n",
        "fp16 = False\n",
        "bf16 = False\n",
        "\n",
        "# Batch size per GPU for training\n",
        "per_device_train_batch_size = 4\n",
        "\n",
        "# Batch size per GPU for evaluation\n",
        "per_device_eval_batch_size = 4\n",
        "\n",
        "# Number of update steps to accumulate the gradients for\n",
        "gradient_accumulation_steps = 1\n",
        "\n",
        "# Enable gradient checkpointing\n",
        "gradient_checkpointing = True\n",
        "\n",
        "# Maximum gradient normal (gradient clipping)\n",
        "max_grad_norm = 0.3\n",
        "\n",
        "# Initial learning rate (AdamW optimizer)\n",
        "learning_rate = 2e-4\n",
        "\n",
        "# Weight decay to apply to all layers except bias/LayerNorm weights\n",
        "weight_decay = 0.001\n",
        "\n",
        "# Optimizer to use\n",
        "optim = \"paged_adamw_32bit\"\n",
        "\n",
        "# Learning rate schedule\n",
        "lr_scheduler_type = \"cosine\"\n",
        "\n",
        "# Number of training steps (overrides num_train_epochs)\n",
        "max_steps = -1\n",
        "\n",
        "# Ratio of steps for a linear warmup (from 0 to learning rate)\n",
        "warmup_ratio = 0.03\n",
        "\n",
        "# Group sequences into batches with same length\n",
        "# Saves memory and speeds up training considerably\n",
        "group_by_length = True\n",
        "\n",
        "# Save checkpoint every X updates steps\n",
        "save_steps = 0\n",
        "\n",
        "# Log every X updates steps\n",
        "logging_steps = 25\n",
        "\n",
        "################################################################################\n",
        "# SFT parameters\n",
        "################################################################################\n",
        "\n",
        "# Maximum sequence length to use\n",
        "max_seq_length = None\n",
        "\n",
        "# Pack multiple short examples in the same input sequence to increase efficiency\n",
        "packing = False\n",
        "\n",
        "# Load the entire model on the GPU 0\n",
        "device_map = {\"\": 0}"
      ],
      "metadata": {
        "id": "ib_We3NLtj2E"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset (you can process it here)\n",
        "dataset = load_dataset(dataset_name, split=\"train\")\n",
        "\n",
        "# Load tokenizer and model with QLoRA configuration\n",
        "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=use_4bit,\n",
        "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=use_nested_quant,\n",
        ")\n",
        "\n",
        "# Check GPU compatibility with bfloat16\n",
        "if compute_dtype == torch.float16 and use_4bit:\n",
        "    major, _ = torch.cuda.get_device_capability()\n",
        "    if major >= 8:\n",
        "        print(\"=\" * 80)\n",
        "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "# Load base model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=device_map\n",
        ")\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1\n",
        "\n",
        "# Load LLaMA tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\" # Fix weird overflow issue with fp16 training\n",
        "\n",
        "# Load LoRA configuration\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    r=lora_r,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "# Set training parameters\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    optim=optim,\n",
        "    save_steps=save_steps,\n",
        "    logging_steps=logging_steps,\n",
        "    learning_rate=learning_rate,\n",
        "    weight_decay=weight_decay,\n",
        "    fp16=fp16,\n",
        "    bf16=bf16,\n",
        "    max_grad_norm=max_grad_norm,\n",
        "    max_steps=max_steps,\n",
        "    warmup_ratio=warmup_ratio,\n",
        "    group_by_length=group_by_length,\n",
        "    lr_scheduler_type=lr_scheduler_type,\n",
        "    report_to=\"tensorboard\"\n",
        ")\n",
        "\n",
        "# Set supervised fine-tuning parameters\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing=packing,\n",
        ")\n",
        "\n",
        "# Train model\n",
        "trainer.train()\n",
        "\n",
        "# Save trained model\n",
        "trainer.model.save_pretrained(new_model)"
      ],
      "metadata": {
        "id": "OJXpOgBFuSrc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433,
          "referenced_widgets": [
            "87de37ef2dc34cfda9d179a499e50463",
            "71a287c30634401bb99286a0ecab6fde",
            "fb3b227610924c9eaea8f4f4f99dbd39",
            "6298f7958c484967bd91d459ab514cc0",
            "120d4b07606949d28790e9e5b3e3f931",
            "757ae8f937044623bb1f60722ac1573a",
            "826356db10e942b38576855b1f0c54a3",
            "83022808e74e40d9b3af7de668ff8505",
            "d84706b1cd3340aeacec7340d6e81c6e",
            "bb249cb5e74e46bc81d48399bb422f85",
            "ee1d34c35f3b4b8799b6047329ce1734"
          ]
        },
        "outputId": "697795fe-a0ae-4ea6-c3e7-6c6881a96251"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87de37ef2dc34cfda9d179a499e50463"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n",
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='188' max='188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [188/188 02:28, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>3.089300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.899200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.801300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.761000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.632200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.484200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>1.523800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir results/runs"
      ],
      "metadata": {
        "id": "crj9svNe4hU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignore warnings\n",
        "logging.set_verbosity(logging.CRITICAL)\n",
        "\n",
        "# Run text generation pipeline with our next model\n",
        "prompt = \"Write a program to add two numbers. Add appropriate comments where necessary\"\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=512)\n",
        "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "frlSLPin4IJ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ec97e1c-1ab9-45de-d6c1-f298194f920b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] Write a program to add two numbers. Add appropriate comments where necessary [/INST]  Sure! Here is a program to add two numbers:\n",
            "```\n",
            "# Write a function to add two numbers.\n",
            "def add_numbers(a, b):\n",
            "    # Calculate the sum of two numbers.\n",
            "    return a + b\n",
            "\n",
            "# Example usage.\n",
            "a = 5\n",
            "b = 3\n",
            "result = add_numbers(a, b)\n",
            "print(result) # Output: 8\n",
            "```\n",
            "Here's a breakdown of the code:\n",
            "\n",
            "1. `def add_numbers(a, b):` - This line defines a function called `add_numbers` that takes two arguments `a` and `b`.\n",
            "2. `return a + b` - This line calculates the sum of `a` and `b` and returns it.\n",
            "3. `a = 5` - This line sets the value of `a` to `5`.\n",
            "4. `b = 3` - This line sets the value of `b` to `3`.\n",
            "5. `result = add_numbers(a, b)` - This line calls the `add_numbers` function with `a` and `b` as arguments and stores the result in `result`.\n",
            "6. `print(result)` - This line prints the result of `add_numbers` function, which is `8`.\n",
            "\n",
            "Note: The comments in the code are optional, but they can help explain what the code is doing and make it easier to understand.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignore warnings\n",
        "logging.set_verbosity(logging.CRITICAL)\n",
        "\n",
        "# Run text generation pipeline with our next model\n",
        "prompt = \"Write a program to create a calculator. Write using object oriented programming and add comments where necessary.\"\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=512)\n",
        "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lICmBKafFEkl",
        "outputId": "432a0e5e-f638-400b-d078-821a0cd72f5b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] Write a program to create a calculator. Write using object oriented programming and add comments where necessary. [/INST]  Sure! Here is an example of how you could create a simple calculator using object-oriented programming:\n",
            "```\n",
            "# Define a class called Calculator\n",
            "class Calculator:\n",
            "    def __init__(self):\n",
            "        # Initialize the calculator object\n",
            "        self.num1 = 0\n",
            "        self.num2 = 0\n",
            "        self.result = 0\n",
            "\n",
            "    # Define methods for addition and subtraction\n",
            "    def add(self, num):\n",
            "        self.num1 = num\n",
            "        self.result = self.num1 + self.num2\n",
            "\n",
            "    def sub(self, num):\n",
            "        self.num2 = num\n",
            "        self.result = self.num1 - self.num2\n",
            "\n",
            "# Create an instance of the calculator class\n",
            "my_calculator = Calculator()\n",
            "\n",
            "# Add some numbers\n",
            "my_calculator.add(5)\n",
            "print(my_calculator.result) # Output: 5\n",
            "\n",
            "# Subtract some numbers\n",
            "my_calculator.sub(2)\n",
            "print(my_calculator.result) # Output: 3\n",
            "```\n",
            "Here's a breakdown of the code:\n",
            "\n",
            "1. `class Calculator:`: This line defines a class called `Calculator`.\n",
            "2. `def __init__(self):`: This line defines an empty function called `__init__` that initializes the calculator object.\n",
            "3. `self.num1 = 0`: This line sets the value of `num1` to 0.\n",
            "4. `self.num2 = 0`: This line sets the value of `num2` to 0.\n",
            "5. `self.result = 0`: This line sets the value of `result` to 0.\n",
            "6. `def add(self, num):`: This line defines a function called `add` that takes a single argument `num`.\n",
            "7. `self.num1 = num`: This line sets the value of `num1` to the value of `num`.\n",
            "8. `self.result = self.num1 + self.num2`: This line calculates the sum of `num1` and `num2` and stores the result in `result`.\n",
            "9. `\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BLSntPxBIWkb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Empty VRAM\n",
        "del model\n",
        "del pipe\n",
        "del trainer\n",
        "import gc\n",
        "gc.collect()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkQCviG0Zta-",
        "outputId": "288dd3db-aaf1-4abd-ee9b-04faf9a3cb13"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19965"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload model in FP16 and merge it with LoRA weights\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    low_cpu_mem_usage=True,\n",
        "    return_dict=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=device_map,\n",
        ")\n",
        "model = PeftModel.from_pretrained(base_model, new_model)\n",
        "model = model.merge_and_unload()\n",
        "\n",
        "# Reload tokenizer to save it\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ],
      "metadata": {
        "id": "QQn30cRtAZ-P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f69919bcbf78422283d4a563bee0f7eb",
            "0ac3a69109a241c68c21bcda25ca62ff",
            "ccb497cf46e249129d13e73f9b1a26a7",
            "40703ce07ae84726b82e923de16a2583",
            "c5573a7a892d48df909ca894e088fda4",
            "7cce49e3f6134d78aa60cab6ebafa2ca",
            "7424a35e355c4844a7b882d4249b5fad",
            "667b211332a0449494084da0acb24564",
            "14b57836cbcb4fc8855503b8112769ac",
            "24dc4767f289473d9ebefea7965dda3e",
            "c8c96a733fc848e98972e1c7773b6dc9"
          ]
        },
        "outputId": "d0f35ae0-4824-4c64-e3be-68a406cc1980"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f69919bcbf78422283d4a563bee0f7eb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignore warnings\n",
        "logging.set_verbosity(logging.CRITICAL)\n",
        "\n",
        "# Run text generation pipeline with our next model\n",
        "prompt = \"Write a program to create a calculator. Write using object oriented programming and add comments where necessary.\"\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=512)\n",
        "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtNWNzHHIeEk",
        "outputId": "68e4b56c-dbce-4973-b9c5-b0d89660e33c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] Write a program to create a calculator. Write using object oriented programming and add comments where necessary. [/INST]  Sure! Here is an example of how you could create a simple calculator using object-oriented programming in Python:\n",
            "```\n",
            "class Calculator:\n",
            "    def __init__(self):\n",
            "        self.num1 = 0\n",
            "        self.num2 = 0\n",
            "        self.result = 0\n",
            "\n",
            "    def add(self):\n",
            "        self.result = self.num1 + self.num2\n",
            "        self.num1 = 0\n",
            "        self.num2 = 0\n",
            "\n",
            "    def subtract(self):\n",
            "        self.result = self.num1 - self.num2\n",
            "        self.num1 = 0\n",
            "        self.num2 = 0\n",
            "\n",
            "    def multiply(self):\n",
            "        self.result = self.num1 * self.num2\n",
            "        self.num1 = 0\n",
            "        self.num2 = 0\n",
            "\n",
            "    def divide(self):\n",
            "        if self.num2 == 0:\n",
            "            raise ValueError(\"Cannot divide by zero!\")\n",
            "        self.result = self.num1 / self.num2\n",
            "        self.num1 = 0\n",
            "        self.num2 = 0\n",
            "\n",
            "    def get_result(self):\n",
            "        return self.result\n",
            "\n",
            "# Create an instance of the Calculator class\n",
            "calculator = Calculator()\n",
            "\n",
            "# Perform calculations\n",
            "calculator.add()\n",
            "calculator.subtract()\n",
            "calculator.multiply()\n",
            "calculator.divide()\n",
            "\n",
            "# Get the result\n",
            "print(calculator.get_result())\n",
            "```\n",
            "Here's how the code works:\n",
            "\n",
            "1. We define a `Calculator` class with four methods: `__init__`, `add`, `subtract`, `multiply`, and `divide`. These methods perform the basic arithmetic operations.\n",
            "2. We create an instance of the `Calculator` class using the `Calculator()` constructor.\n",
            "3. We perform calculations using the `add`, `subtract`, `multiply`, and `divide` methods.\n",
            "4. We get the result of the calculations using the `get_result` method.\n",
            "\n",
            "Note that this is a very basic implementation of a calculator, and you may want to add more features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignore warnings\n",
        "logging.set_verbosity(logging.CRITICAL)\n",
        "\n",
        "# Run text generation pipeline with our next model\n",
        "prompt = \"Write a program to train a linear regression model using sklearn. Use functions to write neat code and explain with comments. Save the model to the model folder. Use the data from data.csv file and use the DATA_USE column for train and test split. Evaluate on RMSE and R^2 values.\"\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=512)\n",
        "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qd20dZu7JPsL",
        "outputId": "cf7c0a3c-e45b-4eb6-f04b-142caa1f462a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] Write a program to train a linear regression model using sklearn. Use functions to write neat code and explain with comments. Save the model to the model folder. Use the data from data.csv file and use the DATA_USE column for train and test split. Evaluate on RMSE and R^2 values. [/INST]  Sure, here is an example of how to train a linear regression model using scikit-learn in Python:\n",
            "```\n",
            "# Import necessary libraries\n",
            "from sklearn.linear_model import LinearRegression\n",
            "from sklearn.model_selection import train_test_split\n",
            "import pandas as pd\n",
            "\n",
            "# Load the data from the data.csv file\n",
            "data = pd.read_csv('data.csv')\n",
            "\n",
            "# Split the data into train and test sets\n",
            "X_train, X_test, y_train, y_test = train_test_split(data.drop('DATA_USE', axis=1), data['DATA_USE'], test_size=0.2, random_state=42)\n",
            "\n",
            "# Train the linear regression model\n",
            "model = LinearRegression()\n",
            "model.fit(X_train, y_train)\n",
            "\n",
            "# Evaluate the model on the test set\n",
            "y_pred = model.predict(X_test)\n",
            "rse = mean_squared_error(y_test, y_pred)\n",
            "r2 = r2_score(y_test, y_pred)\n",
            "print(f'RMSE: {rse:.2f}')\n",
            "print(f'R^2: {r2:.2f}')\n",
            "\n",
            "# Save the model to the model folder\n",
            "with open('model.pkl', 'wb') as file:\n",
            "    pickle.dump(model, file)\n",
            "```\n",
            "Here's an explanation of the code:\n",
            "\n",
            "1. `from sklearn.linear_model import LinearRegression`: Import the LinearRegression class from scikit-learn's linear regression module.\n",
            "2. `from sklearn.model_selection import train_test_split`: Import the train_test_split function from scikit-learn's model selection module. This function is used to split the data into train and test sets.\n",
            "3. `import pandas as pd`: Import the pandas library to read the data from the data.csv file.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignore warnings\n",
        "logging.set_verbosity(logging.CRITICAL)\n",
        "\n",
        "# Run text generation pipeline with our next model\n",
        "prompt = \"Write code to visualize a 4x4 grid of images. Let the 4 plots be 1,2,3,4. For plot #1, it is scatter plot with two numeric variables. For plot #2, it is a bar plot with numeric and categorical variable. For plot #3, it is line plot with time as a varaible. For #4, it is correlation plot. Use matplotlib. Make it aesthetic and appealing.\"\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=512)\n",
        "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdxH6GD6J9Oh",
        "outputId": "88a80b27-99a1-4f38-d467-9381f0023fc5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] Write code to visualize a 4x4 grid of images. Let the 4 plots be 1,2,3,4. For plot #1, it is scatter plot with two numeric variables. For plot #2, it is a bar plot with numeric and categorical variable. For plot #3, it is line plot with time as a varaible. For #4, it is correlation plot. Use matplotlib. Make it aesthetic and appealing. [/INST]  Sure, here is an example of how you could visualize a 4x4 grid of images using matplotlib.\n",
            "```\n",
            "import matplotlib.pyplot as plt\n",
            "import numpy as np\n",
            "\n",
            "# Generate some random data for the plots\n",
            "data = np.random.rand(4, 4)\n",
            "\n",
            "# Plot #1: Scatter plot with two numeric variables\n",
            "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
            "ax.scatter(data[:, 0], data[:, 1], c='blue', s=100)\n",
            "ax.set_xlabel('Variable 1')\n",
            "ax.set_ylabel('Variable 2')\n",
            "\n",
            "# Plot #2: Bar plot with numeric and categorical variable\n",
            "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
            "ax.bar(data[:, 0], data[:, 1], bottom=data[:, 2], color='red')\n",
            "ax.set_xlabel('Category')\n",
            "ax.set_ylabel('Value')\n",
            "\n",
            "# Plot #3: Line plot with time as a variable\n",
            "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
            "ax.plot(data[:, 3], data[:, 0], label='Time')\n",
            "ax.plot(data[:, 3], data[:, 1], label='Time')\n",
            "ax.set_xlabel('Time')\n",
            "ax.set_ylabel('Value')\n",
            "ax.legend()\n",
            "\n",
            "# Plot #4: Correlation plot\n",
            "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
            "ax.scatter(data[:, 0], data[:, 1], c='blue', s=100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignore warnings\n",
        "logging.set_verbosity(logging.CRITICAL)\n",
        "\n",
        "# Run text generation pipeline with our next model\n",
        "prompt = \"Write a Python program to load a CSV file as a DataFrame using pandas.\"\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=512)\n",
        "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ_6PTSmLPQc",
        "outputId": "060bd1be-d78c-4a6b-875d-3818c13de748"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] Write a Python program to load a CSV file as a DataFrame using pandas. [/INST]  Sure! Here is an example of how to load a CSV file as a DataFrame using pandas in Python:\n",
            "```\n",
            "import pandas as pd\n",
            "\n",
            "# Load the CSV file\n",
            "df = pd.read_csv('data.csv')\n",
            "\n",
            "# Print the DataFrame\n",
            "print(df)\n",
            "```\n",
            "In this example, `data.csv` is the name of the CSV file that you want to load. The `read_csv()` function reads the CSV file and returns a DataFrame. The `print()` function prints the DataFrame to the console.\n",
            "\n",
            "You can also specify the path of the CSV file by using the `path` argument, like this:\n",
            "```\n",
            "df = pd.read_csv('/path/to/data.csv')\n",
            "```\n",
            "You can also use `read_csv()` function with other arguments like `header`, `na_values`, `keep`, `nrows`, ` sep`, `quote`, `linetype`, `converters`, `date_parser`, `datetime_parser`, `num_nans`, `float_nans`, `infer`, `engine`, `concatenate_columns`, `usecols`, `useindex`, `srs`, `date_format`, `timezone`, `tz_info`, `na_action`, `keep_default_na`, `na_values`, `na_filter`, `numpy_na`, `pandas_na`, `fill_value`, `fill_na`, `insert_na`, `pad_na`, `trim_nan`, `trim_value`, `trim_na`, `numpy_trim`, `pandas_trim`, `numpy_fill`, `pandas_fill`, `numpy_insert`, `pandas_insert`, `numpy_pad`, `pandas_pad`, `numpy_trim`, `pandas_trim`, `numpy_fill`, `pandas_fill`, `numpy_insert`, `pandas_insert`, `numpy_pad`, `pandas_pad`, `numpy_trim`, `pandas_trim`, `numpy_fill`, `pandas_fill`, `numpy_insert`, `pandas_insert`, `numpy_pad`, `pandas_pad`, `numpy_trim`, `pandas_trim`, `numpy_fill`, `pandas_fill`, `numpy_insert`, `pandas_insert`, `\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignore warnings\n",
        "logging.set_verbosity(logging.CRITICAL)\n",
        "\n",
        "# Run text generation pipeline with our next model\n",
        "prompt = \"Create a class called Student having attributes name, rollno, age, city where student can access these properties through getters and setters methods respectively. Also add constructor method so that when user creates new instance of Student then he must pass values for above parameters otherwise default value would be assigned automatically. Finally display details about this newly created students information.\"\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=512)\n",
        "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgmGwy0eLPTP",
        "outputId": "c29290c1-9eb6-449a-86ca-da7248ed2639"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] Create a class called Student having attributes name, rollno, age, city where student can access these properties through getters and setters methods respectively. Also add constructor method so that when user creates new instance of Student then he must pass values for above parameters otherwise default value would be assigned automatically. Finally display details about this newly created students information. [/INST]  Sure, here is an example of a `Student` class with the attributes you specified, along with getters and setters methods, and a constructor method that assigns default values if they are not provided:\n",
            "```\n",
            "class Student:\n",
            "    def __init__(self, name, rollno, age, city):\n",
            "        self.name = name\n",
            "        self.rollno = rollno\n",
            "        self.age = age\n",
            "        self.city = city\n",
            "\n",
            "    def get_name(self):\n",
            "        return self.name\n",
            "\n",
            "    def get_rollno(self):\n",
            "        return self.rollno\n",
            "\n",
            "    def get_age(self):\n",
            "        return self.age\n",
            "\n",
            "    def get_city(self):\n",
            "        return self.city\n",
            "\n",
            "    def set_name(self, name):\n",
            "        self.name = name\n",
            "\n",
            "    def set_rollno(self, rollno):\n",
            "        self.rollno = rollno\n",
            "\n",
            "    def set_age(self, age):\n",
            "        self.age = age\n",
            "\n",
            "    def set_city(self, city):\n",
            "        self.city = city\n",
            "\n",
            "student = Student(\"John\", 1234, 25, \"New York\")\n",
            "print(student.get_name())  # Output: John\n",
            "print(student.get_rollno())  # Output: 1234\n",
            "print(student.get_age())  # Output: 25\n",
            "print(student.get_city())  # Output: New York\n",
            "\n",
            "# Modifying the student's details\n",
            "student.set_name(\"Jane\")\n",
            "print(student.get_name())  # Output: Jane\n",
            "student.set_rollno(5678)\n",
            "print(student.get_rollno())  # Output: 5678\n",
            "student.set_age(30)\n",
            "print(student.get_age())  # Output: 30\n",
            "student.set_city(\"Los Angeles\")\n",
            "print(student.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignore warnings\n",
        "logging.set_verbosity(logging.CRITICAL)\n",
        "\n",
        "# Run text generation pipeline with our next model\n",
        "prompt = \"minimum cost path in a directed graph via given set of intermediate nodes  stores minimum - cost of path from source\"\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=768)\n",
        "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydoE8a9bLPWG",
        "outputId": "ad11f3a7-7aaa-44ff-9aa8-c1bcb601c8fc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] minimum cost path in a directed graph via given set of intermediate nodes  stores minimum - cost of path from source [/INST]  To find the minimum cost path in a directed graph using intermediate nodes, you can use the following approach:\n",
            "\n",
            "1. Sort the intermediate nodes in non-decreasing order of their costs.\n",
            "2. For each intermediate node, find the minimum cost path from the source node to the intermediate node using the graph's adjacency matrix.\n",
            "3. For each intermediate node, find the minimum cost path from the intermediate node to the destination node using the graph's adjacency matrix.\n",
            "4. Combine the minimum cost paths from steps 2 and 3 to find the minimum cost path from the source node to the destination node.\n",
            "\n",
            "Here is a detailed explanation of the approach:\n",
            "\n",
            "1. Sort the intermediate nodes in non-decreasing order of their costs:\n",
            "\n",
            "Suppose the intermediate nodes are arranged in a list `intermediate_nodes`. The cost of each intermediate node is stored in a list `costs`. To sort the intermediate nodes in non-decreasing order of their costs, you can use the `sort()` function in Python. For example:\n",
            "```python\n",
            "intermediate_nodes = [10, 5, 3, 2, 1]\n",
            "costs = [10, 5, 3, 2, 1]\n",
            "intermediate_nodes.sort(key=lambda x: costs[x])\n",
            "```\n",
            "2. For each intermediate node, find the minimum cost path from the source node to the intermediate node:\n",
            "\n",
            "For each intermediate node `i` in the list `intermediate_nodes`, find the minimum cost path from the source node to node `i` using the graph's adjacency matrix. You can use the `minimum_cost_path()` function to find the minimum cost path. For example:\n",
            "```python\n",
            "def minimum_cost_path(graph, start, end):\n",
            "    # Find the minimum cost path from start to end\n",
            "    path = []\n",
            "    cost = float('inf')\n",
            "    for i in range(len(graph)):\n",
            "        if graph[i][start] == 0:\n",
            "            path.append(i)\n",
            "            cost = min(cost, graph[i][end])\n",
            "    return path, cost\n",
            "```\n",
            "3. For each intermediate node, find the minimum cost path from the intermediate node to the destination node:\n",
            "\n",
            "For each intermediate node `i` in the list `intermediate_nodes`, find the minimum cost path from node `i` to the destination node using the graph's adjacency matrix. You can use the `minimum_cost_path()` function to find the minimum cost path. For example:\n",
            "```python\n",
            "def minimum_cost_path(graph, start, end):\n",
            "    # Find the minimum cost path from start to end\n",
            "    path = []\n",
            "    cost = float('inf')\n",
            "    for i in range(len(graph)):\n",
            "        if graph[i][end] == 0:\n",
            "            path.append(i)\n",
            "            cost = min(cost, graph[i][start])\n",
            "    return path, cost\n",
            "```\n",
            "4. Combine the minimum cost paths from steps 2 and 3 to find the minimum cost path from the source node to the destination node:\n",
            "\n",
            "For each intermediate node `i` in the list `intermediate_nodes`, find the minimum cost path from the source node to node `i` using the `minimum_cost_path()` function. Then, find the minimum cost\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignore warnings\n",
        "logging.set_verbosity(logging.CRITICAL)\n",
        "\n",
        "# Run text generation pipeline with our next model\n",
        "prompt = \"Given two lists sorted in increasing order, write a function to merge them such that the resulting list is also sorted. You can assume that no duplicate entries exist in the original lists.\"\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=768)\n",
        "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EqrL9MbLPc2",
        "outputId": "2760c8b9-22b8-4e4f-ebd6-6af1e1dca1f6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] Given two lists sorted in increasing order, write a function to merge them such that the resulting list is also sorted. You can assume that no duplicate entries exist in the original lists. [/INST]  Sure! Here's a function to merge two sorted lists in increasing order:\n",
            "```\n",
            "def merge_sorted_lists(list1, list2):\n",
            "    result = []\n",
            "    while list1 and list2:\n",
            "        if list1[0] <= list2[0]:\n",
            "            result.append(list1.pop(0))\n",
            "        else:\n",
            "            result.append(list2.pop(0))\n",
            "    return result\n",
            "```\n",
            "Here's how the function works:\n",
            "\n",
            "1. Initialize an empty list `result` to store the merged list.\n",
            "2. While both `list1` and `list2` are not empty, check the first element of each list. If `list1[0]` is less than or equal to `list2[0]`, add the first element of `list1` to `result` and remove it from `list1`. Otherwise, add the first element of `list2` to `result` and remove it from `list2`.\n",
            "3. Repeat step 2 until `list1` and `list2` are empty.\n",
            "4. Return the `result` list, which now contains all the elements from both `list1` and `list2`.\n",
            "\n",
            "Here's an example usage of the function:\n",
            "```\n",
            "list1 = [1, 3, 5, 7]\n",
            "list2 = [2, 4, 6, 8]\n",
            "\n",
            "merged_list = merge_sorted_lists(list1, list2)\n",
            "print(merged_list)  # [1, 2, 3, 4, 5, 6, 7, 8]\n",
            "```\n",
            "Note that the function assumes that the input lists are sorted in increasing order. If the lists are sorted in decreasing order, you can modify the function accordingly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Ignore warnings\n",
        "logging.set_verbosity(logging.CRITICAL)\n",
        "\n",
        "# Run text generation pipeline with our next model\n",
        "prompt = \"Count all the numbers less than 10 ^ 6 whose minimum prime factor is N  Python3 implementation of above approach\"\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=768)\n",
        "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mixxJJdZQaOB",
        "outputId": "36d1a601-4830-408b-eb64-70266766f16f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] Count all the numbers less than 10 ^ 6 whose minimum prime factor is N  Python3 implementation of above approach [/INST]  To count the numbers less than 10^6 whose minimum prime factor is N, we can use the same approach as before.\n",
            "\n",
            "Let's define a function to count the numbers less than 10^6 whose minimum prime factor is N:\n",
            "```python\n",
            "def count_numbers(n):\n",
            "    count = 0\n",
            "    for i in range(1, 10**6):\n",
            "        if i % n == 0 and i % (n-1) == 0:\n",
            "            count += 1\n",
            "    return count\n",
            "```\n",
            "In this function, we iterate from 1 to 10^6 and check if the number is divisible by N. If it is, we check if it is also divisible by N-1. If both conditions are true, we increment the count.\n",
            "\n",
            "Here's an example usage of the function:\n",
            "```python\n",
            "print(count_numbers(3)) # Output: 12\n",
            "```\n",
            "In this example, we pass 3 as the argument to the function, and it returns 12, which is the number of numbers less than 10^6 whose minimum prime factor is 3.\n",
            "\n",
            "Note that this approach is more efficient than the previous one because it avoids checking the divisibility of each number by 2, 3, and 5. Instead, it only checks the divisibility of each number by N and N-1, which are the only prime factors of N.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RJ3fJUssQaQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login\n",
        "\n",
        "model.push_to_hub(new_model, use_temp_dir=False)\n",
        "tokenizer.push_to_hub(new_model, use_temp_dir=False)"
      ],
      "metadata": {
        "id": "x-xPb-_qB0dz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373,
          "referenced_widgets": [
            "c99aff4cfd664ae8a165a27bea0566c8",
            "e4b64cab6b7b418c8a2575ee26839039",
            "c3a4fedc73b3480089ef9d13381471ed",
            "bf722f71c61b4285bcbbf32fd619b3a6",
            "fd11a6148b704c5b9142c5e8de2d3b25",
            "f0bcdaf940d14ad796fc7ac46c8e1e64",
            "b6e821c974674f2290c354238d6c919c",
            "eeba50e8242c4753bfc0ea48e03f9078",
            "7a1f3340688d408092adade75f4baac4",
            "8c887ca9b0eb44fdb8608bf36b5db5c5",
            "e4698337e6b843afac706ab657ca6af9",
            "1af01f1f1aac42b8bff46fe4df8a59ad",
            "eee8731f316244eda5ff0765fd12bf85",
            "f135278e410f4b708435bb80fb630bcf",
            "2e6fc79bf5c149d6b0bc5c52e18debc7",
            "a4b0debc025444a59abd6953b3512c0d",
            "130120644beb48acbc038651459af43c",
            "bf77e97593a349718bdb5fd9bfd28fe3",
            "f7292741953e47699540ef8712fc0d8d",
            "9434350b1b9c4060812feb9ecbf63278",
            "b29647e268414329be56047e522e28b9",
            "27bb18a199ca47108c7a61e9c443de36",
            "33ebb868f3e846f6af1a1a2a8ad6a3cb",
            "1f73f8b4d4da4e74adc135f2a2f6ee65",
            "68da6e6e69c8419895bea2068760534e",
            "6dc1a868e08c4c3b8315116d2c46573b",
            "7a5d714c17374104bb6f5caaa5541c10",
            "1b6c59a51359453c926bfcddb3d0f0ea",
            "dac3669f18284161a58d52f26dffb761",
            "a3511f489f6d47cc8d404ab6f367b29f",
            "20670478612f4b1a8a5f23d71a2609a7",
            "b463153ec04749e38540389efa2981f7",
            "2bb3d36d248a48fba364f14d9e840306"
          ]
        },
        "outputId": "6ed9166c-5f92-4375-eca5-dbb247c0e13a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "    \n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c99aff4cfd664ae8a165a27bea0566c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1af01f1f1aac42b8bff46fe4df8a59ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33ebb868f3e846f6af1a1a2a8ad6a3cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/mlabonne/llama-2-7b-miniguanaco/commit/c81a32fd0b4d39e252326e639d63e75aa68c9a4a', commit_message='Upload tokenizer', commit_description='', oid='c81a32fd0b4d39e252326e639d63e75aa68c9a4a', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}